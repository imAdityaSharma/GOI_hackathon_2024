{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9238585,"sourceType":"datasetVersion","datasetId":5588314},{"sourceId":9238595,"sourceType":"datasetVersion","datasetId":5588322},{"sourceId":9318024,"sourceType":"datasetVersion","datasetId":5644063},{"sourceId":193871887,"sourceType":"kernelVersion"}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-06T07:19:36.268612Z","iopub.execute_input":"2024-09-06T07:19:36.269045Z","iopub.status.idle":"2024-09-06T07:19:36.788795Z","shell.execute_reply.started":"2024-09-06T07:19:36.268992Z","shell.execute_reply":"2024-09-06T07:19:36.786838Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/ogd-goi-test/X_Test_Data_Input.csv\n/kaggle/input/ogd-goi-test/Y_Test_Data_Target.csv\n/kaggle/input/ogd-goi/Y_Train_Data_Target.csv\n/kaggle/input/ogd-goi/X_Train_Data_Input.csv\n/kaggle/input/full-cleaned/full_cleaned.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nfrom scipy.stats.mstats import winsorize","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:36.791018Z","iopub.execute_input":"2024-09-06T07:19:36.791743Z","iopub.status.idle":"2024-09-06T07:19:38.363917Z","shell.execute_reply.started":"2024-09-06T07:19:36.791693Z","shell.execute_reply":"2024-09-06T07:19:38.362417Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.metrics import roc_auc_score, f1_score\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score , accuracy_score","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:38.366135Z","iopub.execute_input":"2024-09-06T07:19:38.366863Z","iopub.status.idle":"2024-09-06T07:19:40.811819Z","shell.execute_reply.started":"2024-09-06T07:19:38.366802Z","shell.execute_reply":"2024-09-06T07:19:40.809381Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Data Read","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import RandomForestRegressor\n\ndef file_read_and_col_verification(path_x: str):\n    xcolumns = [\"ID\", \"Column0\", \"Column1\", \"Column2\", \"Column3\", \"Column4\", \"Column5\", \"Column6\", \"Column7\", \n                \"Column8\", \"Column9\", \"Column10\", \"Column11\", \"Column12\", \"Column13\", \"Column14\", \"Column15\", \n                \"Column16\", \"Column17\", \"Column18\", \"Column19\", \"Column20\", \"Column21\"]\n    try:\n        xdf = pd.read_csv(path_x, header=0)\n    except Exception as e:\n        print(e)\n        return 'file read error'\n    \n    cols = list(xdf.columns)\n    if cols != xcolumns:\n        return \"columns mismatch, check if this is the correct file\"\n    xdf.drop(['Column9','Column14'], inplace=True, axis=1)  # almost 50% null\n    xdf.drop(['Column4', 'Column11', 'Column12', 'Column13'], axis=1, inplace=True)  # highly correlated    \n    return xdf","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-09-06T07:19:40.818669Z","iopub.execute_input":"2024-09-06T07:19:40.819352Z","iopub.status.idle":"2024-09-06T07:19:40.844269Z","shell.execute_reply.started":"2024-09-06T07:19:40.819304Z","shell.execute_reply":"2024-09-06T07:19:40.842808Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def df_x_cleaner(path: str, cols_list: list) -> pd.DataFrame:\n    xdf = file_read_and_col_verification(path)\n    ID = xdf['ID']\n    xdf.drop(['ID'], axis=1, inplace=True)\n    xdf['Column0'] = xdf['Column0'].fillna(1)\n#     print('before imputing')\n#     print(xdf.isnull().sum())\n    imputed_df_sample = xdf.sample(n=100000, random_state=42)\n    # Create a list of boolean conditions\n    conditions = [imputed_df_sample[col].notnull() for col in cols_list]\n    # Combine all conditions using logical AND\n    combined_condition = np.logical_and.reduce(conditions)\n    # Apply the combined condition to filter the DataFrame\n    df_not_missing = imputed_df_sample[combined_condition]\n    for i in range(len(cols_list)):\n        print(f\"####################pass{i}#######################\")\n        \n        try:\n            # Separate feature columns and target column\n            X_train_sub = df_not_missing.drop(cols_list, axis=1)\n            y_train_sub = df_not_missing[cols_list[i]]\n            \n            # Fit the model\n            model = RandomForestRegressor(n_estimators=100, random_state=42)\n            model.fit(X_train_sub, y_train_sub.values.ravel())\n            \n            # Predict missing values\n            X_full_missing = xdf[xdf[cols_list[i]].isnull()].drop(cols_list, axis=1)\n            \n            predicted_values = model.predict(X_full_missing)\n            \n        except Exception as e:\n            print(e)\n            return None\n        \n        # Prepare for merging\n        xdf.reset_index(inplace=True)\n        Temp_col = xdf[xdf[cols_list[i]].isnull()][['index', cols_list[i]]].reset_index(drop=True)\n        Temp_col['predicted'] = np.nan  # Placeholder for predicted values\n\n        prd = pd.DataFrame(predicted_values, columns=['predicted'])\n        prd.reset_index(drop=True, inplace=True)  # Ensure indices match\n        \n        # Join Temp_col and prd on the row index\n        Temp_col['predicted'] = prd['predicted']\n        \n        xdf = xdf.set_index('index').combine_first(Temp_col.set_index('index')).reset_index()\n        xdf[cols_list[i]] = xdf[cols_list[i]].fillna(xdf['predicted'])\n        xdf.drop(['predicted'], axis=1, inplace=True)\n        \n        # Rearrange xdf to match the desired order\n        desired_order = [\"Column0\", \"Column1\", \"Column2\", \"Column3\", \"Column5\", \"Column6\", \"Column7\", \n                         \"Column8\", \"Column10\", \"Column15\",\"Column16\", \"Column17\", \"Column18\", \"Column19\", \n                         \"Column20\", \"Column21\"]\n        xdf = xdf[desired_order]\n    xdf['ID'] = ID   \n    print(xdf.isnull().sum())    \n    return xdf\n","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-09-06T07:19:40.847235Z","iopub.execute_input":"2024-09-06T07:19:40.849177Z","iopub.status.idle":"2024-09-06T07:19:40.869910Z","shell.execute_reply.started":"2024-09-06T07:19:40.849097Z","shell.execute_reply":"2024-09-06T07:19:40.867462Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"try:\n    dfx= pd.read_csv('/kaggle/input/full-cleaned/full_cleaned.csv',header=0)\n    \nexcept:\n    dfx = df_x_cleaner('/kaggle/input/ogd-goi/X_Train_Data_Input.csv', ['Column3', \"Column5\", \"Column6\", \"Column8\", \"Column15\"])\n    dfx.to_csv('full_cleaned.csv')\nyfx = pd.read_csv('/kaggle/input/ogd-goi/Y_Train_Data_Target.csv',header=0).drop('ID',axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:40.872691Z","iopub.execute_input":"2024-09-06T07:19:40.873379Z","iopub.status.idle":"2024-09-06T07:19:47.391606Z","shell.execute_reply.started":"2024-09-06T07:19:40.873302Z","shell.execute_reply":"2024-09-06T07:19:47.389747Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"dfx['Column0']= dfx['Column0'].astype(int)\ndfx['Column2_winsorized'] = dfx['Column2_winsorized'].astype(int)\ndfx['Column16']= dfx['Column16'].astype(int)\ndfx['Column18']= dfx['Column18'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:47.393562Z","iopub.execute_input":"2024-09-06T07:19:47.394010Z","iopub.status.idle":"2024-09-06T07:19:49.169063Z","shell.execute_reply.started":"2024-09-06T07:19:47.393966Z","shell.execute_reply":"2024-09-06T07:19:49.164025Z"},"trusted":true},"execution_count":7,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n","File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'Column2_winsorized'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dfx[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn0\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m dfx[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn0\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m dfx[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn2_winsorized\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdfx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mColumn2_winsorized\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      3\u001b[0m dfx[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn16\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m dfx[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn16\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      4\u001b[0m dfx[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn18\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m dfx[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mColumn18\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n","\u001b[0;31mKeyError\u001b[0m: 'Column2_winsorized'"],"ename":"KeyError","evalue":"'Column2_winsorized'","output_type":"error"}]},{"cell_type":"code","source":"dfx.drop('ID',axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.171031Z","iopub.status.idle":"2024-09-06T07:19:49.171866Z","shell.execute_reply.started":"2024-09-06T07:19:49.171478Z","shell.execute_reply":"2024-09-06T07:19:49.171538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = dfx.copy(deep=True)\n# dfx.skew()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.174131Z","iopub.status.idle":"2024-09-06T07:19:49.174757Z","shell.execute_reply.started":"2024-09-06T07:19:49.174446Z","shell.execute_reply":"2024-09-06T07:19:49.174474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# outlier detection","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nsns.set(style=\"whitegrid\")\nnum_columns = 6\n\nfor i in range(0, len(x.columns), num_columns):\n\n    cols = x.columns[i:i + num_columns]\n\n    plt.figure(figsize=(30, 6))\n    sns.set(style=\"whitegrid\")\n    for j, column in enumerate(cols, 1):\n        plt.subplot(1, num_columns, j)\n        sns.boxplot(y=x[column])\n        plt.title(column)\n    \n    plt.tight_layout()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.176873Z","iopub.status.idle":"2024-09-06T07:19:49.177415Z","shell.execute_reply.started":"2024-09-06T07:19:49.177172Z","shell.execute_reply":"2024-09-06T07:19:49.177196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## - column0, column2, column5, column6, column7, \n## - column8,column10,  column15, column16,column17, \n## - column18, column19, column20, column21\n\nexcept for column2 others have significant outliers","metadata":{}},{"cell_type":"markdown","source":"## columns19, 20 21 needs to balanced, outlier removal wont work on them","metadata":{}},{"cell_type":"markdown","source":"## Column1, Column2_winsorised, Column3, Column5_winsorised, Column6_winsorised, Column7_winsorised, Column8_winsorised âœ…","metadata":{}},{"cell_type":"code","source":"x['Column2_winsorized'] = winsorize(x['Column2'], limits=[0.05, 0.05]) #already good\nx['Column6_winsorized'] = winsorize(x['Column6'], limits=[0, 0.23]) # best possible\nx['Column7_winsorized'] = winsorize(x['Column7'], limits=[0.22, 0.22]) #done works good for now\nx['Column8_winsorized'] = winsorize(x['Column8'], limits=[0, 0.05]) # best possible\nx['Column5_winsorized'] = winsorize(x['Column5'], limits=[0.075, 0.1]) # best i could do\nx.drop(['Column2','Column5','Column6','Column7','Column8'],axis=1,inplace = True)\n\n# x['Column0_winsorized'] = winsorize(x['Column0'], limits=[0.02, 0.02]) not working well\n# x['Column10_winsorized'] = winsorize(x['Column10'], limits=[0, 0.2350]) # not working good, use anotehr technique\n# x['Column15_winsorized'] = winsorize(x['Column15'], limits=[0.05, 0.05]) *1000000 # not working good, use anotehr technique\n# x['Column18_winsorized'] = winsorize(x['Column18'], ) # not working good, use anotehr technique\n\n\n# x['Column16_winsorized'] = winsorize(x['Column16'], limits=[0, 0.01]) not possible\n# x['Column17_winsorized'] = winsorize(x['Column17'], limits=[0, 0.05]) not possible\n# x['Column19_winsorized'] = winsorize(x['Column19'], limits=[0.05, 0.05]) not possible\n# x['Column20_winsorized'] = winsorize(x['Column20'], limits=[0.05, 0.05]) not possible\n# x['Column21_winsorized'] = winsorize(x['Column21'], limits=[0.05, 0.05]) not possible\n\nfor i in range(0, len(x.columns), num_columns):\n    cols = x.columns[i:i + num_columns]\n    plt.figure(figsize=(20, 5))\n    sns.set(style=\"whitegrid\")\n    for j, column in enumerate(cols, 1):\n        plt.subplot(1, num_columns, j)\n        sns.boxplot(y=x[column])\n        plt.title(column)\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.180205Z","iopub.status.idle":"2024-09-06T07:19:49.180744Z","shell.execute_reply.started":"2024-09-06T07:19:49.180455Z","shell.execute_reply":"2024-09-06T07:19:49.180477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### tried robust scalar, no good","metadata":{}},{"cell_type":"code","source":"\nfrom sklearn.preprocessing import RobustScaler\nscaler = RobustScaler()\n# x['Column0_scaled'] = scaler.fit_transform(x[['Column0']])\n# x['Column5_scaled'] = scaler.fit_transform(x[['Column5']]) # best i could do\n# x['Column10_scaled'] = scaler.fit_transform(x[['Column10']])\n# x['Column15_scaled'] = scaler.fit_transform(x[['Column15']])\n# x['Column18_scaled'] = scaler.fit_transform(x[['Column18']])\n\n# log_cols = x[['Column0_scaled','Column5_scaled','Column10_scaled','Column15_scaled','Column18_scaled']]\n# # x['Column16_winsorized'] = winsorize(x['Column16'], limits=[0, 0.01]) not possible\n# # x['Column17_winsorized'] = winsorize(x['Column17'], limits=[0, 0.05]) not possible\n# # x['Column19_winsorized'] = winsorize(x['Column19'], limits=[0.05, 0.05]) not possible\n# # x['Column20_winsorized'] = winsorize(x['Column20'], limits=[0.05, 0.05]) not possible\n# # x['Column21_winsorized'] = winsorize(x['Column21'], limits=[0.05, 0.05]) not possible\n\n# for i in range(0, len(log_cols.columns), num_columns):\n#     cols = log_cols.columns[i:i + num_columns]\n#     plt.figure(figsize=(20, 5))\n#     sns.set(style=\"whitegrid\")\n#     for j, column in enumerate(cols, 1):\n#         plt.subplot(1, num_columns, j)\n#         sns.boxplot(y=log_cols[column])\n#         plt.title(column)\n#     plt.tight_layout()\n#     plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.182239Z","iopub.status.idle":"2024-09-06T07:19:49.182751Z","shell.execute_reply.started":"2024-09-06T07:19:49.182518Z","shell.execute_reply":"2024-09-06T07:19:49.182545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.columns","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.184768Z","iopub.status.idle":"2024-09-06T07:19:49.185210Z","shell.execute_reply.started":"2024-09-06T07:19:49.185005Z","shell.execute_reply":"2024-09-06T07:19:49.185026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x.drop(['Column0', 'Column1', 'Column2', 'Column3', 'Column5', 'Column6',\n#        'Column7', 'Column8', 'Column15', 'Column16', 'Column17',\n#        'Column18', 'Column19', 'Column20', 'Column21',            'Column0_scaled', 'Column5_scaled'])","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.188182Z","iopub.status.idle":"2024-09-06T07:19:49.189152Z","shell.execute_reply.started":"2024-09-06T07:19:49.188790Z","shell.execute_reply":"2024-09-06T07:19:49.188833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x['Column2_winsorized'] = x['Column2_winsorized'].astype(int)\n# x['Column0']= x['Column0'].astype(int)\n# x['Column16']= x['Column16'].astype(int)\n# x['Column18']= x['Column18'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.190959Z","iopub.status.idle":"2024-09-06T07:19:49.191475Z","shell.execute_reply.started":"2024-09-06T07:19:49.191201Z","shell.execute_reply":"2024-09-06T07:19:49.191224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x['Column3'].sum()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.193257Z","iopub.status.idle":"2024-09-06T07:19:49.193725Z","shell.execute_reply.started":"2024-09-06T07:19:49.193487Z","shell.execute_reply":"2024-09-06T07:19:49.193531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imblearn.over_sampling import SMOTENC\nfrom collections import Counter\n\n# Assuming you have the data in a pandas DataFrame 'data'\ncate = ['Column0','Column10','Column16','Column17','Column18','Column19','Column20','Column21']\n# to be continued\n\nsmote_nc = SMOTENC(categorical_features=cate, random_state=42)\n\n# Apply SMOTEnc\nX_resampled, y_resampled = smote_nc.fit_resample(x, yfx)\n\n# Convert back to DataFrame for convenience (optional)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.195446Z","iopub.status.idle":"2024-09-06T07:19:49.196099Z","shell.execute_reply.started":"2024-09-06T07:19:49.195785Z","shell.execute_reply":"2024-09-06T07:19:49.195817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_resampled.shape #value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.198315Z","iopub.status.idle":"2024-09-06T07:19:49.199311Z","shell.execute_reply.started":"2024-09-06T07:19:49.198659Z","shell.execute_reply":"2024-09-06T07:19:49.198691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_resampled = pd.DataFrame(X_resampled, columns=x.columns)\ndf_resampled['Target'] = y_resampled\n\n# print(f\"Original class distribution: {np.bincount(yfx['target'])}\")\n# print(f\"Resampled class distribution: {np.bincount(y_resampled)}\")\ndf_resampled.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.201519Z","iopub.status.idle":"2024-09-06T07:19:49.202142Z","shell.execute_reply.started":"2024-09-06T07:19:49.201833Z","shell.execute_reply":"2024-09-06T07:19:49.201865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.skew()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.204677Z","iopub.status.idle":"2024-09-06T07:19:49.205177Z","shell.execute_reply.started":"2024-09-06T07:19:49.204950Z","shell.execute_reply":"2024-09-06T07:19:49.204974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_resampled.skew() #[cate].nunique()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.207258Z","iopub.status.idle":"2024-09-06T07:19:49.207944Z","shell.execute_reply.started":"2024-09-06T07:19:49.207612Z","shell.execute_reply":"2024-09-06T07:19:49.207651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sns.heatmap(dfx.corr())\nsns.heatmap(x.corr())","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.210118Z","iopub.status.idle":"2024-09-06T07:19:49.210755Z","shell.execute_reply.started":"2024-09-06T07:19:49.210425Z","shell.execute_reply":"2024-09-06T07:19:49.210454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfx[[\"Column19\"]].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.212068Z","iopub.status.idle":"2024-09-06T07:19:49.212710Z","shell.execute_reply.started":"2024-09-06T07:19:49.212378Z","shell.execute_reply":"2024-09-06T07:19:49.212409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x['Column0_log'] = np.log1p(x['Column0'])  # log1p is equivalent to log(1 + x), which handles zeroes\n\n# # Check the transformed distribution\n# plt.figure(figsize=(10, 6))\n# sns.histplot(x['Column0_log'], bins=30, kde=True)\n# plt.title('Log-Transformed Distribution of Column0')\n# plt.xlabel('Log(Column0 + 1)')\n# plt.ylabel('Frequency')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.215912Z","iopub.status.idle":"2024-09-06T07:19:49.217417Z","shell.execute_reply.started":"2024-09-06T07:19:49.216359Z","shell.execute_reply":"2024-09-06T07:19:49.216397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# freq = x['Column0'].value_counts()\n# weights = (1 / freq)*10000\n# data['Column0_weight'] = data['Column0'].map(weights)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.219259Z","iopub.status.idle":"2024-09-06T07:19:49.220012Z","shell.execute_reply.started":"2024-09-06T07:19:49.219662Z","shell.execute_reply":"2024-09-06T07:19:49.219697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x['Column0'].map(weights)*100000","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.222373Z","iopub.status.idle":"2024-09-06T07:19:49.223050Z","shell.execute_reply.started":"2024-09-06T07:19:49.222728Z","shell.execute_reply":"2024-09-06T07:19:49.222761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.figure(figsize=(10, 6))\n# sns.boxplot(x['Column0'].map(weights)*100000)\n# # plt.title('Log-Transformed Distribution of Column0')\n# # plt.xlabel('Log(Column0 + 1)')\n# plt.ylabel('Frequency')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.225301Z","iopub.status.idle":"2024-09-06T07:19:49.226141Z","shell.execute_reply.started":"2024-09-06T07:19:49.225747Z","shell.execute_reply":"2024-09-06T07:19:49.225783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x['Column0'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.228091Z","iopub.status.idle":"2024-09-06T07:19:49.229070Z","shell.execute_reply.started":"2024-09-06T07:19:49.228641Z","shell.execute_reply":"2024-09-06T07:19:49.228688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Q1 = x[\"Column0\"].quantile(0.25)\n# Q3 = x[\"Column0\"].quantile(0.75)\n# IQR = Q3 - Q1\n\n# # Find rows where any value is an outlier\n# outliers = x[\"Column0\"][((x[\"Column0\"] < (Q1 - 1.5 * IQR)) | (x[\"Column0\"] > (Q3 + 1.5 * IQR)))]\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.231730Z","iopub.status.idle":"2024-09-06T07:19:49.232375Z","shell.execute_reply.started":"2024-09-06T07:19:49.232057Z","shell.execute_reply":"2024-09-06T07:19:49.232090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# skewness handling","metadata":{}},{"cell_type":"code","source":"# x.skew()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.233883Z","iopub.status.idle":"2024-09-06T07:19:49.234574Z","shell.execute_reply.started":"2024-09-06T07:19:49.234233Z","shell.execute_reply":"2024-09-06T07:19:49.234265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# skewness_handle = [\"Column0\",\"Column3\",\"Column5\",\"Column6\",\"Column7\",\"Column8\",\"Column10\",\"Column15\",\"Column16\",\"Column17\",\"Column18\",\"Column19\",\"Column20\",\"Column21\"]","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.237914Z","iopub.status.idle":"2024-09-06T07:19:49.238365Z","shell.execute_reply.started":"2024-09-06T07:19:49.238164Z","shell.execute_reply":"2024-09-06T07:19:49.238184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x['Column5_transformed'] = np.arcsinh(x['Column5'])\n# x['Column5_transformed'].skew()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.240619Z","iopub.status.idle":"2024-09-06T07:19:49.241106Z","shell.execute_reply.started":"2024-09-06T07:19:49.240888Z","shell.execute_reply":"2024-09-06T07:19:49.240911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model functions ","metadata":{}},{"cell_type":"code","source":"# Calculate metrics for each model\ndef mats(y_pred_xgb,y_pred_rfr,y_pred_LGBMR,y_test):\n    metrics = {\n                'XGB': {\n                    'Accuracy': accuracy_score(y_test, y_pred_xgb),\n                    'MAE': mean_absolute_error(y_test, y_pred_xgb),\n                    'MSE': mean_squared_error(y_test, y_pred_xgb),\n                    'R2': r2_score(y_test, y_pred_xgb),\n                    \"rmse\" : np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n                    },\n                'RFR': {\n                    'Accuracy': accuracy_score(y_test, y_pred_rfr),\n                    'MAE': mean_absolute_error(y_test, y_pred_rfr),\n                    'MSE': mean_squared_error(y_test, y_pred_rfr),\n                    'R2': r2_score(y_test, y_pred_rfr),\n                    'rmse_rfr': np.sqrt(mean_squared_error(y_test, y_pred_rfr))\n                    },\n                'LGBMR': {\n                    'Accuracy': accuracy_score(y_test, y_pred_LGBMR),\n                    'MAE': mean_absolute_error(y_test, y_pred_LGBMR),\n                    'MSE': mean_squared_error(y_test, y_pred_LGBMR),\n                    'R2': r2_score(y_test, y_pred_LGBMR),\n                    'rmse_LGBMR':  np.sqrt(mean_squared_error(y_test, y_pred_LGBMR))\n                    }\n                }\n\n    metrics_df = pd.DataFrame(metrics).T\n    print(metrics_df)\n\n\n\ndef roc_auc(xgb_model,rfr_model,LGBMR_model,X_test,y_test):\n    # Assuming your target variable y_test is binary (0 and 1)\n    y_pred_prob_xgb = xgb_model.predict_proba(X_test)[:, 1]\n    y_pred_prob_rfr = rfr_model.predict_proba(X_test)[:, 1]  # If RandomForestClassifier is used\n    y_pred_prob_LGBMR = LGBMR_model.predict_proba(X_test)[:, 1]\n\n    # Calculate AUC\n    auc_xgb = roc_auc_score(y_test, y_pred_prob_xgb)\n    auc_rfr = roc_auc_score(y_test, y_pred_prob_rfr)\n    auc_LGBMR = roc_auc_score(y_test, y_pred_prob_LGBMR)\n    \n    y_pred_xgb_binary = (y_pred_prob_xgb > 0.5).astype(int)\n    y_pred_rfr_binary = (y_pred_prob_rfr > 0.5).astype(int)\n    y_pred_LGBMR_binary = (y_pred_prob_LGBMR > 0.5).astype(int)\n\n    # Calculate F1 Score\n    f1_xgb = f1_score(y_test, y_pred_xgb_binary)\n    f1_rfr = f1_score(y_test, y_pred_rfr_binary)\n    f1_LGBMR = f1_score(y_test, y_pred_LGBMR_binary)\n\n    # Print AUC values\n    print(f\"AUC (XGB): {auc_xgb}\")\n    print(f\"AUC (RFR): {auc_rfr}\")\n    print(f\"AUC (LGBMR): {auc_LGBMR}\")\n\ndef confusion(xgb_model,rfr_model,LGBMR_model,X_test,y_test):\n       \n    y_pred_prob_xgb = xgb_model.predict_proba(X_test)[:, 1]\n    y_pred_prob_rfr = rfr_model.predict_proba(X_test)[:, 1]  # If RandomForestClassifier is used\n    y_pred_prob_LGBMR = LGBMR_model.predict_proba(X_test)[:, 1]\n\n    # Convert probabilities to binary predictions\n    y_pred_xgb_binary = (y_pred_prob_xgb > 0.5).astype(int)\n    y_pred_rfr_binary = (y_pred_prob_rfr > 0.5).astype(int)\n    y_pred_LGBMR_binary = (y_pred_prob_LGBMR > 0.5).astype(int)\n\n    # Compute confusion matrices\n    conf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb_binary)\n    conf_matrix_rfr = confusion_matrix(y_test, y_pred_rfr_binary)\n    conf_matrix_LGBMR = confusion_matrix(y_test, y_pred_LGBMR_binary)\n\n    # Visualize confusion matrices\n    def plot_confusion_matrices(cms, titles):\n        plt.figure(figsize=(15, 5))  # Adjust size for 3 subplots in a row\n        for i, (cm, title) in enumerate(zip(cms, titles), 1):\n            plt.subplot(1, len(cms), i)  # Create subplot for each confusion matrix\n            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                        xticklabels=['Class 0', 'Class 1'], \n                        yticklabels=['Class 0', 'Class 1'])\n            plt.title(title)\n            plt.xlabel('Predicted Label')\n            plt.ylabel('True Label')\n        plt.tight_layout()  # Adjust subplots to fit into figure area\n        plt.show()\n\n    cms = [conf_matrix_xgb, conf_matrix_rfr, conf_matrix_LGBMR]\n    titles = ['XGB', 'RFR', 'LGBMR']\n    plot_confusion_matrices(cms, titles)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.244219Z","iopub.status.idle":"2024-09-06T07:19:49.245012Z","shell.execute_reply.started":"2024-09-06T07:19:49.244483Z","shell.execute_reply":"2024-09-06T07:19:49.244533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"mats(y_pred_xgb,y_pred_rfr,y_pred_LGBMR,y_test) <br>\nroc_auc(xgb_model,rfr_model,LGBMR_model,X_test,y_test) <br>\nconfusion(xgb_model,rfr_model,LGBMR_model)\n","metadata":{}},{"cell_type":"code","source":"# Replace LogisticRegression with LinearRegression\ndef stackm(df_x: pd.DataFrame, df_y: pd.DataFrame):\n    xgb_model = XGBClassifier()\n    rfr_model = RandomForestClassifier()\n    LGBMR_model = LGBMClassifier()\n\n    # Corrected variable assignment\n    X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.3, random_state=42)\n    \n    # Fit the models\n    xgb_model.fit(X_train, y_train)\n    rfr_model.fit(X_train, y_train)\n    LGBMR_model.fit(X_train, y_train)\n    \n    return xgb_model, rfr_model, LGBMR_model, X_test, y_test\n","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.246541Z","iopub.status.idle":"2024-09-06T07:19:49.247045Z","shell.execute_reply.started":"2024-09-06T07:19:49.246819Z","shell.execute_reply":"2024-09-06T07:19:49.246841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming df_x and df_y are your feature matrix and target vector, respectively\nxgb_model, rfr_model, LGBMR_model, xtest1, ytest1 = stackm(X_resampled, y_resampled)\n\n# on cleaned data, and some outliers removed\ny_pred_xgb = xgb_model.predict(xtest1)\ny_pred_rfr = rfr_model.predict(xtest1)\ny_pred_LGBMR = LGBMR_model.predict(xtest1)\nprint()\nmats(y_pred_xgb,y_pred_rfr,y_pred_LGBMR,ytest1)\nprint()\nroc_auc(xgb_model,rfr_model,LGBMR_model,xtest1,ytest1)\nprint()\nconfusion(xgb_model,rfr_model,LGBMR_model,xtest1,ytest1)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.248632Z","iopub.status.idle":"2024-09-06T07:19:49.249076Z","shell.execute_reply.started":"2024-09-06T07:19:49.248870Z","shell.execute_reply":"2024-09-06T07:19:49.248890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xgb_model2, rfr_model2, LGBMR_model2, xtest2, ytest2 = stackm(dfx, yfx)\n\n# on cleaned data, and some outliers removed\ny_pred_xgb2 = xgb_model2.predict(xtest2)\ny_pred_rfr2 = rfr_model2.predict(xtest2)\ny_pred_LGBMR2 = LGBMR_model2.predict(xtest2)\nprint()\nmats(y_pred_xgb2,y_pred_rfr2,y_pred_LGBMR2,ytest2)\nprint()\nroc_auc(xgb_model2,rfr_model2,LGBMR_model2,xtest2,ytest2)\nprint()\nconfusion(xgb_model2,rfr_model2,LGBMR_model2,xtest2,ytest2)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.251087Z","iopub.status.idle":"2024-09-06T07:19:49.251575Z","shell.execute_reply.started":"2024-09-06T07:19:49.251328Z","shell.execute_reply":"2024-09-06T07:19:49.251348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(xgb_model2)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T07:19:49.253427Z","iopub.status.idle":"2024-09-06T07:19:49.254009Z","shell.execute_reply.started":"2024-09-06T07:19:49.253770Z","shell.execute_reply":"2024-09-06T07:19:49.253794Z"},"trusted":true},"execution_count":null,"outputs":[]}]}